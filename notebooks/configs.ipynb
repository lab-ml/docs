{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs\n",
    "\n",
    "`.. currentmodule:: labml.configs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configurations provide an API to easily manage hyper-parameters\n",
    "and other configurable parameters of the experiments.\n",
    "The configuration of each experiment run are stored.\n",
    "These can be viewed on [Dashboard](https://github.com/vpj/labmlml_dashboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from labml import tracker, monit, loop, experiment, logger\n",
    "from labml.configs import BaseConfigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a configuration class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceConfigs(BaseConfigs):\n",
    "    use_cuda: bool = True\n",
    "    cuda_device: int = 0\n",
    "\n",
    "    device: any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculated configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DeviceConfigs.calc(DeviceConfigs.device)\n",
    "def cuda(c: DeviceConfigs):\n",
    "    is_cuda = c.use_cuda and torch.cuda.is_available()\n",
    "    if not is_cuda:\n",
    "        return torch.device(\"cpu\")\n",
    "    else:\n",
    "        if c.cuda_device < torch.cuda.device_count():\n",
    "            return torch.device(f\"cuda:{c.cuda_device}\")\n",
    "        else:\n",
    "            logger.log(f\"Cuda device index {c.cuda_device} higher than \"\n",
    "                       f\"device count {torch.cuda.device_count()}\", Text.warning)\n",
    "            return torch.device(f\"cuda:{torch.cuda.device_count() - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inheriting and re-using configuration classes\n",
    "\n",
    "Configs classes can be inherited. This lets you separate configs into modules instead of passing [monolithic config object](https://www.reddit.com/r/MachineLearning/comments/g1vku4/d_antipatterns_in_open_sourced_ml_research_code/).\n",
    "\n",
    "You can even inherit a entire experiment setups and make a few modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs(DeviceConfigs):\n",
    "    model_size: int = 1024\n",
    "    input_size: int = 10\n",
    "    output_size: int = 10\n",
    "        \n",
    "    model: any = 'two_hidden_layer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining configurations options\n",
    "\n",
    "You can specify multiple config calculator functions.\n",
    "You pick which one to use by its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHiddenLayerModule(nn.Module):\n",
    "    def __init__(self, input_size: int, model_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_size, model_size)\n",
    "        self.output_fc = nn.Linear(model_size, output_size)\n",
    "    \n",
    "    def forward(x: torch.Tensor):\n",
    "        x = F.relu(self.input_fc(x))\n",
    "        return self.output_fc(x)\n",
    "    \n",
    "# This is just for illustration purposes, ideally you should have a configuration\n",
    "# for number of hidden layers.\n",
    "# A real world example would be different architectures, like a dense network vs a CNN\n",
    "class TwoHiddenLayerModule(nn.Module):\n",
    "    def __init__(self, input_size: int, model_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.input_fc = nn.Linear(input_size, model_size)\n",
    "        self.middle_fc = nn.Linear(model_size, model_size)\n",
    "        self.output_fc = nn.Linear(model_size, output_size)\n",
    "    \n",
    "    def forward(x: torch.Tensor):\n",
    "        x = F.relu(self.input_fc(x))\n",
    "        x = F.relu(self.middle_fc(x))\n",
    "        return self.output_fc(x)\n",
    "\n",
    "\n",
    "@Configs.calc(Configs.model)\n",
    "def one_hidden_layer(c: Configs):\n",
    "    return OneHiddenLayerModule(c.input_size, c.model_size, c.output_size)\n",
    "\n",
    "@Configs.calc(Configs.model)\n",
    "def two_hidden_layer(c: Configs):\n",
    "    return TwoHiddenLayerModule(c.input_size, c.model_size, c.output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the configurations calculators pass only the needed parameters and not the whole config object.\n",
    "The library forces you to do that.\n",
    "\n",
    "However, you can directly set the model as an option, with `__init__` accepting `Configs` as a parameter,\n",
    "it is not a usage pattern we encourage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the experiment\n",
    "\n",
    "Here's how you run an experiment with the configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "<span style=\"color: #60C6C8\">model: </span><strong>OneHiddenLayerModule(</strong>\n",
       "<strong>  (input_fc): Linear(in_features=10, out_features=1024, bi ...</strong></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = Configs()\n",
    "conf.model = 'one_hidden_layer'\n",
    "experiment.create(name='test_configs')\n",
    "experiment.calculate_configs(conf)\n",
    "logger.inspect(model=conf.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "<strong><span style=\"text-decoration: underline\">test_configs</span></strong>: <span style=\"color: #208FFB\">20ced7ee946011eab224acde48001122</span>\n",
       "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"citation\"</span></strong>\n",
       "<span style=\"text-decoration: underline\">Configs:</span>\n",
       "\t<span style=\"color: #60C6C8\">cuda_device</span><span style=\"color: #C5C1B4\"> = </span><strong>0</strong>\t\n",
       "\t<span style=\"color: #60C6C8\">device</span><span style=\"color: #C5C1B4\"> = </span><strong>cpu</strong>\t<span style=\"color: #C5C1B4\">cuda</span>\n",
       "\t<span style=\"color: #60C6C8\">input_size</span><span style=\"color: #C5C1B4\"> = </span><strong>10</strong>\t\n",
       "\t<span style=\"color: #60C6C8\"><strong><span style=\"color: #DDB62B\">model</span></strong></span><span style=\"color: #C5C1B4\"> = </span><strong>OneHiddenLayerModule(  (input_fc): Linea...</strong>\tone_hidden_layer<span style=\"color: #C5C1B4\">\t[</span>two_hidden_layer<span style=\"color: #C5C1B4\">]</span>\n",
       "\t<span style=\"color: #60C6C8\">model_size</span><span style=\"color: #C5C1B4\"> = </span><strong>1024</strong>\t\n",
       "\t<span style=\"color: #60C6C8\">output_size</span><span style=\"color: #C5C1B4\"> = </span><strong>10</strong>\t\n",
       "\t<span style=\"color: #60C6C8\">use_cuda</span><span style=\"color: #C5C1B4\"> = </span><strong>True</strong>\t\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
